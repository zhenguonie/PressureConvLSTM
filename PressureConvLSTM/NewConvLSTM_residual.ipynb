{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('py37_gpu': conda)"
  },
  "interpreter": {
   "hash": "7eb94436339a4d99a2031a7d84a488e9d2aa13ef5b3c819e73cf9b08757e932b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np \r\n",
    "import os\r\n",
    "import math\r\n",
    "import pandas as pd\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from tensorflow.keras import layers,Sequential,Model \r\n",
    "from keras.utils import np_utils\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from utils.ReadData import readData\r\n",
    "from utils.SetGen import SetGen\r\n",
    "from utils.DataAug import DataAugement"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\r\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n",
    "\r\n",
    "gpus = tf.config.list_physical_devices('GPU')\r\n",
    "tf.config.experimental.set_memory_growth(gpus[0],True)\r\n",
    "print('Num GPUs Available:', len(tf.config.experimental.list_physical_devices('GPU')))\r\n",
    "\r\n",
    "from tensorflow.python.client import device_lib\r\n",
    "def get_available_gpus():\r\n",
    "    local_divice_protos = device_lib.list_local_devices()\r\n",
    "    # print(local_divice_protos)\r\n",
    "    return [x for x in local_divice_protos if x.device_type == 'GPU']   \r\n",
    "print(get_available_gpus())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_LB= 'PlantarPressureDataset/LBNew'\r\n",
    "path_RB = 'PlantarPressureDataset/RBNew'\r\n",
    "path_N = 'PlantarPressureDataset/NormalNew'\r\n",
    "\r\n",
    "LBTotal, LBLeft, LBRight = readData().Extract(path = path_LB)\r\n",
    "RBTotal, RBLeft, RBRight = readData().Extract(path = path_RB)\r\n",
    "NTotal, NLeft, NRight = readData().Extract(path = path_N)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Data = LBTotal + RBTotal + NTotal\r\n",
    "Data = np.reshape(Data,(np.shape(Data)+(1,)))\r\n",
    "\r\n",
    "Label = []\r\n",
    "for i in range(len(LBTotal)):\r\n",
    "    Label.append(0)\r\n",
    "for i in range(len(RBTotal)):\r\n",
    "    Label.append(1)\r\n",
    "for i in range(len(NTotal)):\r\n",
    "    Label.append(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Xtr, ytr, Xval, yval = SetGen().GetSets(Data, Label, 0.9, 0.1)\r\n",
    "H = 48\r\n",
    "W = 34"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Gen = DataAugement(Xtr,ytr)\r\n",
    "Xtr, ytr =Gen.dataAug(angle = 5,rate = 0.35)\r\n",
    "Dim = np.size(Xtr,axis = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ytr= np_utils.to_categorical(ytr,3)\r\n",
    "yval = np_utils.to_categorical(yval,3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = keras.Sequential(name = 'NewConvLSTM')\r\n",
    "bs = 32\r\n",
    "hidden_feature = 128\r\n",
    "ts = 60\r\n",
    "h = 48\r\n",
    "w = 34\r\n",
    "channel = 1\r\n",
    "\r\n",
    "input_data = keras.Input((ts,h,w,channel))\r\n",
    "x = layers.BatchNormalization()(input_data)\r\n",
    "fil = np.array([4,8,16])\r\n",
    "\r\n",
    "for i in range(3):\r\n",
    "    x = layers.Conv3D(filters = 2**(i+2), kernel_size = (1,3,3), padding='same')(x)\r\n",
    "    x = layers.BatchNormalization()(x)\r\n",
    "    x = layers.ReLU()(x)\r\n",
    "\r\n",
    "\r\n",
    "f1 = layers.Conv3D(16, (1, 2, 2), padding='same' )(x)\r\n",
    "f2 = layers.Conv3D(16, (1, 3, 3), padding='same' )(x)\r\n",
    "f3 = layers.Conv3D(16, (1, 4, 4), padding='same' )(x)\r\n",
    "\r\n",
    "\r\n",
    "newInput = tf.concat([f1,f2,f3,x],axis = -1)\r\n",
    "PDC0 = layers.Conv3D(32,(1,1,1),padding = 'same' )(newInput)\r\n",
    "RPDC = layers.ReLU()(PDC0)\r\n",
    "BN_RPDC = layers.BatchNormalization()(RPDC)\r\n",
    "Residual = PDC0+BN_RPDC\r\n",
    "ConvLSTM0 = layers.ConvLSTM2D(16,kernel_size = 3, padding = 'same',return_sequences = 'True')(Residual)\r\n",
    "MaxPool0 = layers.MaxPool3D(pool_size = (1,2,2))(ConvLSTM0)\r\n",
    "BN0 = layers.BatchNormalization()(MaxPool0)\r\n",
    "ConvLSTM1 = layers.ConvLSTM2D(32,kernel_size = 3, padding = 'same',return_sequences = 'True')(BN0)\r\n",
    "MaxPool1 = layers.MaxPool3D(pool_size = (1,2,2))(ConvLSTM1)\r\n",
    "BN1 = layers.BatchNormalization()(MaxPool1)\r\n",
    "ConvLSTM2 = layers.ConvLSTM2D(128,kernel_size = 3, padding = 'same', dropout=0.1)(BN1)\r\n",
    "BN2 = layers.BatchNormalization()(ConvLSTM2)\r\n",
    "Maxpool1 = layers.MaxPool2D(pool_size = (2,2))(BN2)\r\n",
    "Flatten1 = layers.Flatten()(Maxpool1)\r\n",
    "\r\n",
    "FC1 = layers.Dense(1000,activation = 'relu')(Flatten1)\r\n",
    "DP0 = layers.Dropout(0.1)(FC1)\r\n",
    "FC2 = layers.Dense(128,activation = 'relu')(DP0)\r\n",
    "DP1 = layers.Dropout(0.1)(FC2)\r\n",
    "FC3 = layers.Dense(16,activation = 'relu')(FC2)\r\n",
    "outPut = layers.Dense(3,activation = 'softmax')(FC3)\r\n",
    "\r\n",
    "model  = keras.Model(inputs = input_data, outputs = outPut)\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BS = 32\r\n",
    "N = np.size(Xtr,axis = 0)\r\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\r\n",
    "# with tf.device('/GPU:0'):\r\n",
    "#     history = model.fit(Xtr,ytr,batch_size = BS, epochs= N//BS, validation_data = (Xval,yval),callbacks=[callback])\r\n",
    "history = model.fit(Xtr,ytr,batch_size = BS, epochs= N//BS, validation_data = (Xval,yval))"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('model/model1',save_format='h5')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save_weights('weights/model1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(history.history).to_csv('history/training_log1.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# plt.title(\"Acc\")\r\n",
    "# plt.semilogy(history.history['accuracy'], label='Train acc')\r\n",
    "# plt.semilogy(history.history['val_accuracy'], label='Validation acc')\r\n",
    "# plt.xlabel('Epochs')\r\n",
    "# plt.ylabel('accuracy')\r\n",
    "# plt.legend()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#  tf.keras.utils.plot_model(model, to_file='convLSTM_new.png', show_shapes=True, show_layer_names=True,rankdir='TB', dpi=900, expand_nested=True)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}